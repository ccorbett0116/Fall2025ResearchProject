{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/ccorbett0116/Fall2025ResearchProject/blob/main/Research_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Project Title:\n",
    "# Authors: Jose Henriquez, Cole Corbett\n",
    "## Description:\n",
    "The deployment of medical AI systems across different hospitals raises critical questions about whether fairness and representation quality can be reliably transferred across clinical domains. Models trained on one hospital’s imaging data are often reused in new environments where patient demographics, imaging devices, and diagnostic practices differ substantially, potentially resulting in unintended bias against certain groups. This project investigates this challenge by studying fairness-aware representation alignment in medical imaging. The student will train contrastive learning models—such as SimCLR—independently on two large-scale chest X-ray datasets: CheXpert (from Stanford Hospital) and MIMIC-CXR (from Beth Israel Deaconess Medical Center). After learning embeddings in each domain, the student will apply domain alignment techniques such as Procrustes alignment to map representations from the CheXpert embedding space into the MIMIC-CXR space. The aligned embeddings will then be evaluated using fairness metrics designed for representation spaces, including demographic subgroup alignment, intra- vs. inter-group embedding disparity, and cluster-level demographic parity. The expected outcome is a rigorous understanding of whether fairness properties learned in one hospital setting preserve, degrade, or improve when transferred to another, revealing how robust model fairness is to realworld clinical domain shifts. A practical use case involves a healthcare network seeking to deploy a model trained at a major academic hospital (e.g., Stanford) into a community hospital setting: this project helps determine whether the transferred representations remain equitable across patient groups such as older adults, women, or specific disease cohorts. The findings will support responsible AI deployment in healthcare by highlighting the conditions under which fairness is stable across institutions and identifying scenarios where domain-specific mitigation strategies may be required."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Process is probably different on colab, this is hyperspecific to me because I'm working on Pycharm connected to my WSL\n",
    "import sys\n",
    "import os\n",
    "!{sys.executable} -m pip install kagglehub polars numpy\n",
    "#We're going to use polars because it's significantly faster, it's build on rust and enables multi-threaded processing as well as some memory optimizations over pandas.\n",
    "\n",
    "# Install PyTorch with CUDA 13.0 support (LINUX Link (May work for windows??))\n",
    "!{sys.executable} -m pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130\n",
    "\n",
    "# Install PyTorch Lightning and Lightning Bolts for SimCLR\n",
    "!{sys.executable} -m pip install pytorch-lightning lightning-bolts\n",
    "\n",
    "# Install sklearn and matplotlib for analysis\n",
    "!{sys.executable} -m pip install scikit-learn matplotlib"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Imports\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "import polars as pol\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, silhouette_score, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "base_model=\"resnet50\"\n",
    "max_epochs = 30\n",
    "max_epochs_mimic = 60\n",
    "proj_dim = 512 # How many dimensions to project the image into\n",
    "base_lr = 1e-3\n",
    "temperature = 0.5\n",
    "batch_size = 128\n",
    "\n",
    "num_workers = 12 # This one just effects cpu utilization/training time\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download datasets\n",
    "\n",
    "path_chexpert = kagglehub.dataset_download(\"mimsadiislam/chexpert\")\n",
    "print(\"Path to chexpert dataset files:\", path_chexpert)\n",
    "\n",
    "path_mimic = kagglehub.dataset_download(\"itsanmol124/mimic-cxr\")\n",
    "print(\"Path to mimic dataset files:\", path_mimic)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dir_chexpert = os.path.join(path_chexpert, \"CheXpert-v1.0-small\")\n",
    "dir_mimic = path_mimic\n",
    "\n",
    "train_csv_chexpert = os.path.join(dir_chexpert, \"train.csv\")\n",
    "valid_csv_chexpert = os.path.join(dir_chexpert, \"valid.csv\")\n",
    "full_csv_mimic = os.path.join(dir_mimic, \"mimic-cxr.csv\")\n",
    "\n",
    "df_complete_mimic = pol.read_csv(full_csv_mimic)\n",
    "df_train_chexpert = pol.read_csv(train_csv_chexpert)\n",
    "df_valid_chexpert = pol.read_csv(valid_csv_chexpert)\n",
    "\n",
    "df_train_mimic = df_complete_mimic.filter(pol.col(\"split\") == \"train\")\n",
    "df_valid_mimic = df_complete_mimic.filter(pol.col(\"split\") == \"valid\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_train_mimic.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_train_chexpert.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(dir_mimic+\"/train\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use Tensor Cores efficiently on 5080\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "import ast\n",
    "\n",
    "# -----------------------\n",
    "# SimCLR augmentations\n",
    "# -----------------------\n",
    "simclr_transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomApply(\n",
    "        [T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)],\n",
    "        p=0.8,\n",
    "    ),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.ToTensor(),\n",
    "    # CXRs are essentially grayscale; simple normalization is fine as a start\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Single-dataset SimCLR Dataset\n",
    "# -----------------------\n",
    "class SimCLRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Unlabeled dataset for SimCLR: returns (view1, view2) per image.\n",
    "    This handles ONE dataset (CheXpert OR MIMIC).\n",
    "    \"\"\"\n",
    "    def __init__(self, df, root, path_col, transform=None, is_mimic=False):\n",
    "        self.transform = transform\n",
    "        self.is_mimic = is_mimic\n",
    "        \n",
    "        # df is a Polars DataFrame; df[path_col] is a Series → .to_list()\n",
    "        rel_paths = df[path_col].to_list()\n",
    "        \n",
    "        # Parse MIMIC paths if needed (they're stored as string lists)\n",
    "        if is_mimic:\n",
    "            parsed_paths = []\n",
    "            for p in rel_paths:\n",
    "                # Parse string representation of list: \"['files/p16/...']\" -> 'files/p16/...'\n",
    "                if isinstance(p, str) and p.startswith('['):\n",
    "                    try:\n",
    "                        path_list = ast.literal_eval(p)\n",
    "                        if path_list and len(path_list) > 0:\n",
    "                            parsed_paths.append(path_list[0])  # Take first element\n",
    "                    except:\n",
    "                        print(f\"Warning: Could not parse path: {p}\")\n",
    "                else:\n",
    "                    parsed_paths.append(p)\n",
    "            rel_paths = parsed_paths\n",
    "        \n",
    "        self.paths = [os.path.join(root, p) for p in rel_paths]\n",
    "\n",
    "        print(f\"Total images for this SimCLR dataset: {len(self.paths)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is None:\n",
    "            raise ValueError(\"SimCLRDataset requires a transform.\")\n",
    "\n",
    "        xi = self.transform(img)\n",
    "        xj = self.transform(img)\n",
    "        return xi, xj\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Build DataLoaders\n",
    "# -----------------------\n",
    "\n",
    "simclr_train_chexpert = SimCLRDataset(\n",
    "    df=df_train_chexpert,\n",
    "    root=path_chexpert,\n",
    "    path_col=\"Path\",      # CheXpert image path column\n",
    "    transform=simclr_transform,\n",
    "    is_mimic=False,\n",
    ")\n",
    "\n",
    "simclr_train_loader_chexpert = DataLoader(\n",
    "    simclr_train_chexpert,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n",
    "\n",
    "simclr_train_mimic = SimCLRDataset(\n",
    "    df=df_train_mimic,\n",
    "    root=dir_mimic,\n",
    "    path_col=\"filename\",     # MIMIC image path column\n",
    "    transform=simclr_transform,\n",
    "    is_mimic=True,        # Enable MIMIC path parsing\n",
    ")\n",
    "\n",
    "simclr_train_loader_mimic = DataLoader(\n",
    "    simclr_train_mimic,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use Tensor Cores efficiently on 5080\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# -----------------------\n",
    "# SimCLR augmentations\n",
    "# -----------------------\n",
    "simclr_transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomApply(\n",
    "        [T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)],\n",
    "        p=0.8,\n",
    "    ),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.ToTensor(),\n",
    "    # CXRs are essentially grayscale; simple normalization is fine as a start\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Single-dataset SimCLR Dataset\n",
    "# -----------------------\n",
    "class SimCLRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Unlabeled dataset for SimCLR: returns (view1, view2) per image.\n",
    "    This handles ONE dataset (CheXpert OR MIMIC).\n",
    "    \"\"\"\n",
    "    def __init__(self, df, root, path_col, transform=None):\n",
    "        self.transform = transform\n",
    "        self.root = root\n",
    "        \n",
    "        # df is a Polars DataFrame; df[path_col] is a Series → .to_list()\n",
    "        rel_paths = df[path_col].to_list()\n",
    "        self.paths = [os.path.join(root, p) for p in rel_paths]\n",
    "\n",
    "        print(f\"Total images for this SimCLR dataset: {len(self.paths)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is None:\n",
    "            raise ValueError(\"SimCLRDataset requires a transform.\")\n",
    "\n",
    "        xi = self.transform(img)\n",
    "        xj = self.transform(img)\n",
    "        return xi, xj\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Build DataLoaders\n",
    "# -----------------------\n",
    "\n",
    "# CheXpert\n",
    "simclr_train_chexpert = SimCLRDataset(\n",
    "    df=df_train_chexpert,\n",
    "    root=path_chexpert,      # CheXpert paths include the subdirectory\n",
    "    path_col=\"Path\",\n",
    "    transform=simclr_transform,\n",
    ")\n",
    "\n",
    "simclr_train_loader_chexpert = DataLoader(\n",
    "    simclr_train_chexpert,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# MIMIC Train\n",
    "simclr_train_mimic = SimCLRDataset(\n",
    "    df=df_train_mimic,\n",
    "    root=path_mimic+\"/train\",    # Images are in train/ directory\n",
    "    path_col=\"filename\",     # MIMIC uses 'filename' column\n",
    "    transform=simclr_transform,\n",
    ")\n",
    "\n",
    "simclr_train_loader_mimic = DataLoader(\n",
    "    simclr_train_mimic,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model: str = \"resnet34\",\n",
    "        out_dim: int = 128,\n",
    "        lr: float = 1e-3,\n",
    "        temperature: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # -------- Encoder (backbone) --------\n",
    "        if base_model == \"resnet34\":\n",
    "            backbone = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "        elif base_model == \"resnet50\":\n",
    "            backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported base_model: {base_model}\")\n",
    "\n",
    "        feat_dim = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.encoder = backbone\n",
    "\n",
    "        # -------- Projection head --------\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim, out_dim),\n",
    "        )\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)           # [B, feat_dim]\n",
    "        z = self.projector(h)         # [B, out_dim]\n",
    "        z = F.normalize(z, dim=1)     # L2-normalize\n",
    "        return z\n",
    "\n",
    "    def nt_xent_loss(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        NT-Xent (InfoNCE) loss used in SimCLR.\n",
    "        z_i, z_j: [B, D] normalized embeddings for the two views\n",
    "        \"\"\"\n",
    "        batch_size = z_i.size(0)\n",
    "        z = torch.cat([z_i, z_j], dim=0)   # [2B, D]\n",
    "\n",
    "        # Cosine similarity matrix: [2B, 2B]\n",
    "        sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "        sim = sim / self.temperature\n",
    "\n",
    "        # Mask out self-similarity on diagonal\n",
    "        self_mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "        sim = sim.masked_fill(self_mask, float(\"-inf\"))\n",
    "\n",
    "        # Positive for each i is i+batch_size (wrap around)\n",
    "        pos_indices = torch.arange(2 * batch_size, device=z.device)\n",
    "        pos_indices = (pos_indices + batch_size) % (2 * batch_size)\n",
    "\n",
    "        loss = F.cross_entropy(sim, pos_indices)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_i, x_j = batch\n",
    "        z_i = self(x_i)\n",
    "        z_j = self(x_j)\n",
    "        loss = self.nt_xent_loss(z_i, z_j)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.trainer.max_epochs\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# -----------------------\n",
    "# Loggers\n",
    "# -----------------------\n",
    "\n",
    "tb_logger_chexpert = TensorBoardLogger(\n",
    "    save_dir=\"tb_logs\",\n",
    "    name=\"simclr_chexpert\"\n",
    ")\n",
    "\n",
    "tb_logger_mimic = TensorBoardLogger(\n",
    "    save_dir=\"tb_logs\",\n",
    "    name=\"simclr_mimic\"\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# CheXpert SimCLR\n",
    "# -----------------------\n",
    "simclr_chexpert = SimCLR(\n",
    "    base_model=base_model,\n",
    "    out_dim=proj_dim,\n",
    "    lr=base_lr,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "ckpt_chexpert = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/simclr_chexpert\",\n",
    "    filename=\"simclr-chexpert-{epoch:02d}-{train_loss:.4f}\",\n",
    "    save_top_k=3,\n",
    "    monitor=\"train_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "trainer_chexpert = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"auto\",\n",
    "    devices=1,\n",
    "    precision=\"bf16\" if torch.cuda.is_available() else \"32\",\n",
    "    callbacks=[ckpt_chexpert, lr_monitor],\n",
    "    logger=tb_logger_chexpert,\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# MIMIC SimCLR\n",
    "# -----------------------\n",
    "simclr_mimic = SimCLR(\n",
    "    base_model=base_model,\n",
    "    out_dim=proj_dim,\n",
    "    lr=base_lr,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "ckpt_mimic = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/simclr_mimic\",\n",
    "    filename=\"simclr-mimic-{epoch:02d}-{train_loss:.4f}\",\n",
    "    save_top_k=3,\n",
    "    monitor=\"train_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "trainer_mimic = pl.Trainer(\n",
    "    max_epochs=max_epochs_mimic,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"auto\",\n",
    "    devices=1,\n",
    "    precision=\"bf16\" if torch.cuda.is_available() else \"32\",\n",
    "    callbacks=[ckpt_mimic, lr_monitor],\n",
    "    logger=tb_logger_mimic,\n",
    "    log_every_n_steps=50,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=== Training SimCLR on CheXpert ===\")\n",
    "trainer_chexpert.fit(simclr_chexpert, simclr_train_loader_chexpert)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=== Training SimCLR on MIMIC ===\")\n",
    "trainer_mimic.fit(simclr_mimic, simclr_train_loader_mimic)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load trained SimCLR models\n",
    "simclr_chexpert = SimCLR.load_from_checkpoint(\"./checkpoints/simclr_chexpert/last.ckpt\")\n",
    "simclr_mimic = SimCLR.load_from_checkpoint(\"./checkpoints/simclr_mimic/last.ckpt\")\n",
    "\n",
    "simclr_chexpert.eval().cuda()\n",
    "simclr_mimic.eval().cuda()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===============================\n",
    "# Validation Transform (NO AUGS)\n",
    "# ===============================\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Validation Datasets\n",
    "# ===============================\n",
    "chexpert_val_ds = SimCLRDataset(\n",
    "    df=df_valid_chexpert,\n",
    "    root=path_chexpert,\n",
    "    path_col=\"Path\",\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "mimic_val_ds = SimCLRDataset(\n",
    "    df=df_valid_mimic,\n",
    "    root=path_mimic + \"/valid\",\n",
    "    path_col=\"filename\",\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Validation DataLoaders\n",
    "# ===============================\n",
    "chexpert_val_loader = DataLoader(\n",
    "    chexpert_val_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "mimic_val_loader = DataLoader(\n",
    "    mimic_val_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Embedding Extraction Function\n",
    "# ===============================\n",
    "def extract_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    all_embeds = []\n",
    "    with torch.no_grad():\n",
    "        for (x_i, _) in loader:  # only need one view\n",
    "            x_i = x_i.to(model.device)\n",
    "            z = model(x_i)\n",
    "            all_embeds.append(z.cpu())\n",
    "\n",
    "    return torch.cat(all_embeds, dim=0)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Extract Embeddings\n",
    "# ===============================\n",
    "emb_chexpert = extract_embeddings(simclr_chexpert, chexpert_val_loader)\n",
    "emb_mimic   = extract_embeddings(simclr_mimic, mimic_val_loader)\n",
    "\n",
    "print(\"CheXpert embeddings:\", emb_chexpert.shape)\n",
    "print(\"MIMIC embeddings:\", emb_mimic.shape)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.save(emb_chexpert, \"emb_chexpert.pt\")\n",
    "torch.save(emb_mimic, \"emb_mimic.pt\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Procrustes Alignment - Stratified Approach\n",
    "\n",
    "This cell performs **Procrustes alignment** to map CheXpert embeddings into MIMIC-CXR embedding space by finding an optimal rotation matrix. The two SimCLR models learned different \"coordinate systems\" for their embeddings, and Procrustes rotates one to match the other while preserving distances. We use the **stratified approach** because it samples equally from each disease category, ensuring that the alignment is guided by semantically matched pairs rather than random pairings. This creates a more accurate rotation matrix since we're explicitly teaching it that \"pneumonia in CheXpert space should map to pneumonia in MIMIC space\" for all 10 diseases, rather than hoping random samples happen to align well."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================\n",
    "# Stratified Procrustes Alignment\n",
    "# =========================================\n",
    "\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "\n",
    "\n",
    "disease_columns = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "    'Enlarged Cardiomediastinum', 'Lung Lesion', 'Lung Opacity',\n",
    "    'Pleural Effusion', 'Pneumonia', 'Pneumothorax'\n",
    "]\n",
    "\n",
    "# =========================================\n",
    "# Stratified Sampling Across Diseases\n",
    "# =========================================\n",
    "def procrustes_stratified(emb_source, emb_target,\n",
    "                         labels_source, labels_target,\n",
    "                         disease_columns, samples_per_disease=100):\n",
    "    \"\"\"\n",
    "    Sample pairs from each disease category for balanced alignment.\n",
    "    Ensures all diseases contribute to the alignment.\n",
    "    \"\"\"\n",
    "    all_pairs_source = []\n",
    "    all_pairs_target = []\n",
    "\n",
    "    for disease in disease_columns:\n",
    "        # Get positive samples for this disease\n",
    "        mask_src = labels_source[disease] == 1\n",
    "        mask_tgt = labels_target[disease] == 1\n",
    "\n",
    "        indices_src = np.where(mask_src)[0]\n",
    "        indices_tgt = np.where(mask_tgt)[0]\n",
    "\n",
    "        if len(indices_src) == 0 or len(indices_tgt) == 0:\n",
    "            print(f\"Skipping {disease}: insufficient samples\")\n",
    "            continue\n",
    "\n",
    "        # Sample pairs\n",
    "        n_samples = min(len(indices_src), len(indices_tgt), samples_per_disease)\n",
    "        sampled_src = np.random.choice(indices_src, n_samples, replace=False)\n",
    "        sampled_tgt = np.random.choice(indices_tgt, n_samples, replace=False)\n",
    "\n",
    "        all_pairs_source.extend(sampled_src)\n",
    "        all_pairs_target.extend(sampled_tgt)\n",
    "\n",
    "        print(f\"{disease}: {n_samples} pairs\")\n",
    "\n",
    "    print(f\"\\nTotal pairs: {len(all_pairs_source)}\")\n",
    "\n",
    "    # Get paired embeddings\n",
    "    X = emb_source[all_pairs_source].cpu().numpy()\n",
    "    Y = emb_target[all_pairs_target].cpu().numpy()\n",
    "\n",
    "    # Center and align\n",
    "    X_mean = X.mean(axis=0)\n",
    "    Y_mean = Y.mean(axis=0)\n",
    "    X_centered = X - X_mean\n",
    "    Y_centered = Y - Y_mean\n",
    "\n",
    "    R, scale = orthogonal_procrustes(X_centered, Y_centered)\n",
    "\n",
    "    # Apply to ALL source embeddings\n",
    "    X_all = emb_source.cpu().numpy()\n",
    "    X_all_centered = X_all - X_mean\n",
    "    X_all_aligned = X_all_centered @ R + Y_mean\n",
    "\n",
    "    return X_all_aligned, R, X_mean, Y_mean, all_pairs_source, all_pairs_target\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# VISUALIZATION FUNCTION\n",
    "# =========================================\n",
    "def visualize_alignment(emb_before_source, emb_before_target,\n",
    "                       emb_after_source, emb_after_target,\n",
    "                       n_samples=1000, perplexity=30):\n",
    "    \"\"\"\n",
    "    Visualize embeddings before and after alignment using t-SNE.\n",
    "    \"\"\"\n",
    "    # Sample for visualization (t-SNE is slow on large datasets)\n",
    "    n_viz = min(n_samples, len(emb_before_source), len(emb_before_target))\n",
    "\n",
    "    idx_src = np.random.choice(len(emb_before_source), n_viz, replace=False)\n",
    "    idx_tgt = np.random.choice(len(emb_before_target), n_viz, replace=False)\n",
    "\n",
    "    # Before alignment\n",
    "    emb_before = np.vstack([\n",
    "        emb_before_source[idx_src],\n",
    "        emb_before_target[idx_tgt]\n",
    "    ])\n",
    "\n",
    "    # After alignment\n",
    "    emb_after = np.vstack([\n",
    "        emb_after_source[idx_src],\n",
    "        emb_after_target[idx_tgt]\n",
    "    ])\n",
    "\n",
    "    # t-SNE\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "    print(\"Running t-SNE on before-alignment embeddings...\")\n",
    "    emb_2d_before = tsne.fit_transform(emb_before)\n",
    "\n",
    "    print(\"Running t-SNE on after-alignment embeddings...\")\n",
    "    emb_2d_after = tsne.fit_transform(emb_after)\n",
    "\n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Before\n",
    "    ax1.scatter(emb_2d_before[:n_viz, 0], emb_2d_before[:n_viz, 1],\n",
    "               label=\"CheXpert\", alpha=0.6, s=20)\n",
    "    ax1.scatter(emb_2d_before[n_viz:, 0], emb_2d_before[n_viz:, 1],\n",
    "               label=\"MIMIC\", alpha=0.6, s=20, color=\"red\")\n",
    "    ax1.set_title(\"Before Procrustes Alignment\", fontsize=14)\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "\n",
    "    # After\n",
    "    ax2.scatter(emb_2d_after[:n_viz, 0], emb_2d_after[:n_viz, 1],\n",
    "               label=\"CheXpert (aligned)\", alpha=0.6, s=20)\n",
    "    ax2.scatter(emb_2d_after[n_viz:, 0], emb_2d_after[n_viz:, 1],\n",
    "               label=\"MIMIC\", alpha=0.6, s=20, color=\"red\")\n",
    "    ax2.set_title(\"After Procrustes Alignment\", fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTE STRATIFIED ALIGNMENT\n",
    "# =========================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Stratified Procrustes Alignment by Disease\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "emb_aligned, R, mean_src, mean_tgt, pairs_src, pairs_tgt = procrustes_stratified(\n",
    "    emb_chexpert, emb_mimic,\n",
    "    df_valid_chexpert, df_valid_mimic,\n",
    "    disease_columns,\n",
    "    samples_per_disease=200\n",
    ")\n",
    "\n",
    "visualize_alignment(\n",
    "    emb_chexpert.cpu().numpy(), emb_mimic.cpu().numpy(),\n",
    "    emb_aligned, emb_mimic.cpu().numpy(),\n",
    "    n_samples=1000\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# SAVE ALIGNED EMBEDDINGS\n",
    "# =========================================\n",
    "torch.save(torch.from_numpy(emb_aligned), \"emb_chexpert_aligned_stratified.pt\")\n",
    "torch.save({\n",
    "    'rotation_matrix': R,\n",
    "    'source_mean': mean_src,\n",
    "    'target_mean': mean_tgt,\n",
    "    'method': 'stratified',\n",
    "    'pairs_source': pairs_src,\n",
    "    'pairs_target': pairs_tgt\n",
    "}, \"procrustes_transform_stratified.pt\")\n",
    "\n",
    "print(\"\\nAligned embeddings saved!\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"CheXpert columns:\", df_valid_chexpert.columns)\n",
    "print(\"MIMIC columns:\", df_valid_mimic.columns)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def evaluate_fairness_by_disease(emb_before, emb_after, demographics, df_labels,\n",
    "                                 disease_columns, group_col='Sex'):\n",
    "    \"\"\"\n",
    "    Check fairness within each disease category (more meaningful than K-means).\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for disease in disease_columns:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Disease: {disease}\")\n",
    "        print('='*70)\n",
    "\n",
    "        # Get samples with this disease\n",
    "        mask = (df_labels[disease] == 1).to_numpy()\n",
    "\n",
    "        if mask.sum() < 10:  # Skip if too few samples\n",
    "            print(f\"Skipping {disease}: only {mask.sum()} samples\")\n",
    "            continue\n",
    "\n",
    "        disease_emb_before = emb_before[mask]\n",
    "        disease_emb_after = emb_after[mask]\n",
    "\n",
    "        # Filter demographics (handle Polars DataFrame)\n",
    "        disease_demos_data = {}\n",
    "        for col in demographics.columns:\n",
    "            disease_demos_data[col] = demographics[col].to_numpy()[mask]\n",
    "        disease_demos = pol.DataFrame(disease_demos_data)\n",
    "\n",
    "        # Check demographic distribution\n",
    "        print(f\"\\nDemographic distribution in {disease} cases ({mask.sum()} total):\")\n",
    "        demo_dist = disease_demos[group_col].value_counts()\n",
    "        print(demo_dist)\n",
    "\n",
    "        # Skip if only one demographic group\n",
    "        unique_groups = disease_demos[group_col].unique().to_list()\n",
    "        unique_groups = [g for g in unique_groups if g is not None]\n",
    "        if len(unique_groups) < 2:\n",
    "            print(f\"Skipping fairness analysis: only one demographic group present\")\n",
    "            continue\n",
    "\n",
    "        # METRIC 1: Subgroup alignment within this disease\n",
    "        print(f\"\\n--- Subgroup Alignment Score (within {disease}) ---\")\n",
    "        print(\"BEFORE Alignment:\")\n",
    "        sas_before, _ = subgroup_alignment_score(disease_emb_before, disease_demos, group_col)\n",
    "        for pair, dist in sas_before.items():\n",
    "            print(f\"  {pair}: {dist:.4f}\")\n",
    "\n",
    "        print(\"\\nAFTER Alignment:\")\n",
    "        sas_after, _ = subgroup_alignment_score(disease_emb_after, disease_demos, group_col)\n",
    "        for pair, dist in sas_after.items():\n",
    "            print(f\"  {pair}: {dist:.4f}\")\n",
    "            if pair in sas_before:\n",
    "                change = ((dist - sas_before[pair]) / sas_before[pair]) * 100\n",
    "                print(f\"    Change: {change:+.2f}%\")\n",
    "\n",
    "        # METRIC 2: Intra/Inter-group disparity within this disease\n",
    "        print(f\"\\n--- Intra/Inter-Group Disparity (within {disease}) ---\")\n",
    "        print(\"BEFORE Alignment:\")\n",
    "        disparity_before = intra_inter_group_disparity(disease_emb_before, disease_demos, group_col)\n",
    "\n",
    "        print(\"\\nAFTER Alignment:\")\n",
    "        disparity_after = intra_inter_group_disparity(disease_emb_after, disease_demos, group_col)\n",
    "\n",
    "        # Store results\n",
    "        results[disease] = {\n",
    "            'n_samples': mask.sum(),\n",
    "            'demographics': demo_dist,\n",
    "            'subgroup_alignment': {'before': sas_before, 'after': sas_after},\n",
    "            'disparity': {'before': disparity_before, 'after': disparity_after}\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def visualize_disease_fairness(results, metric='subgroup_alignment'):\n",
    "    \"\"\"\n",
    "    Visualize fairness metrics across diseases.\n",
    "    \"\"\"\n",
    "    diseases = list(results.keys())\n",
    "\n",
    "    # Extract metric values\n",
    "    before_vals = []\n",
    "    after_vals = []\n",
    "\n",
    "    for disease in diseases:\n",
    "        if metric == 'subgroup_alignment':\n",
    "            # Get first pair distance (assuming binary demographic like Male/Female)\n",
    "            before_dict = results[disease]['subgroup_alignment']['before']\n",
    "            after_dict = results[disease]['subgroup_alignment']['after']\n",
    "\n",
    "            if before_dict and after_dict:\n",
    "                before_vals.append(list(before_dict.values())[0])\n",
    "                after_vals.append(list(after_dict.values())[0])\n",
    "            else:\n",
    "                before_vals.append(0)\n",
    "                after_vals.append(0)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    x = np.arange(len(diseases))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x - width/2, before_vals, width, label='Before Alignment', alpha=0.8)\n",
    "    ax.bar(x + width/2, after_vals, width, label='After Alignment', alpha=0.8, color='orange')\n",
    "\n",
    "    ax.set_xlabel('Disease', fontsize=12)\n",
    "    ax.set_ylabel('Subgroup Distance', fontsize=12)\n",
    "    ax.set_title('Demographic Fairness Across Diseases', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(diseases, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DISEASE-SPECIFIC FAIRNESS EVALUATION: SEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "disease_fairness_sex = evaluate_fairness_by_disease(\n",
    "    emb_before=emb_chexpert.cpu().numpy(),\n",
    "    emb_after=emb_aligned,\n",
    "    demographics=df_valid_chexpert_demo,\n",
    "    df_labels=df_valid_chexpert_demo,\n",
    "    disease_columns=disease_columns,  # The 10 overlapping diseases\n",
    "    group_col='Sex'\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "visualize_disease_fairness(disease_fairness_sex, metric='subgroup_alignment')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DISEASE-SPECIFIC FAIRNESS EVALUATION: AGE GROUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "disease_fairness_age = evaluate_fairness_by_disease(\n",
    "    emb_before=emb_chexpert.cpu().numpy(),\n",
    "    emb_after=emb_aligned,\n",
    "    demographics=df_valid_chexpert_demo,\n",
    "    df_labels=df_valid_chexpert_demo,\n",
    "    disease_columns=disease_columns,\n",
    "    group_col='Age_Group'\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "visualize_disease_fairness(disease_fairness_age, metric='subgroup_alignment')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "EVERYTING BELOW HERE DISREGARD FOR NOW"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Evaluation of Embeddings\n",
    "\n",
    "We visualize and quantitatively evaluate the learned SimCLR embeddings to understand how well the model captures meaningful structure in the data.\n",
    "\n",
    "**t-SNE (t-distributed Stochastic Neighbor Embedding):**  \n",
    "t-SNE is a nonlinear dimensionality reduction technique that maps high-dimensional embeddings (e.g., 128-D SimCLR vectors) into 2D or 3D space while preserving local neighborhoods. This allows us to visually inspect whether images with similar features or labels cluster together in embedding space.\n",
    "\n",
    "**Silhouette Score:**  \n",
    "The silhouette score quantifies cluster quality. For each point \\(i\\), it is defined as:  \n",
    "s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
    "where \\(a(i)\\) is the average intra-cluster distance and \\(b(i)\\) is the average nearest-cluster distance. Scores close to 1 indicate tight, well-separated clusters; scores near 0 or negative indicate overlapping or poorly formed clusters.\n",
    "\n",
    "**K-Nearest Neighbors (KNN) Accuracy:**  \n",
    "KNN on the embeddings provides a downstream quantitative measure of representation quality. By predicting labels using the nearest neighbors in embedding space, we assess whether the learned embeddings preserve semantic similarity. Higher accuracy indicates that images with similar labels are close together in embedding space, reflecting the model's ability to learn discriminative and meaningful features.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "# Combine embeddings\n",
    "all_emb = torch.cat([emb_chexpert, emb_mimic], dim=0).cpu().numpy()\n",
    "\n",
    "# Create labels for coloring: 0 = CheXpert, 1 = MIMIC\n",
    "labels = np.array([0]*emb_chexpert.shape[0] + [1]*emb_mimic.shape[0])\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "emb_2d = tsne.fit_transform(all_emb)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(emb_2d[labels==0, 0], emb_2d[labels==0, 1], s=10, alpha=0.7, label=\"CheXpert\", color=\"blue\")\n",
    "plt.scatter(emb_2d[labels==1, 0], emb_2d[labels==1, 1], s=10, alpha=0.7, label=\"MIMIC\", color=\"red\")\n",
    "plt.title(\"t-SNE of CheXpert and MIMIC embeddings\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"CheXpert columns:\", df_valid_chexpert.columns)\n",
    "print(\"MIMIC columns:\", df_valid_mimic.columns)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CheXpert validation labels\n",
    "chexpert_label_cols = [\n",
    "    'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
    "    'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation',\n",
    "    'Pneumonia', 'Atelectasis', 'Pneumothorax',\n",
    "    'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices'\n",
    "]\n",
    "chexpert_val_labels = df_valid_chexpert.select(chexpert_label_cols).to_numpy()\n",
    "\n",
    "# MIMIC validation labels\n",
    "mimic_label_cols = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "    'Enlarged Cardiomediastinum', 'Lung Lesion', 'Lung Opacity',\n",
    "    'Normal', 'Pleural Effusion', 'Pneumonia', 'Pneumothorax'\n",
    "]\n",
    "mimic_val_labels = df_valid_mimic.select(mimic_label_cols).to_numpy()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To quantitatively evaluate our embeddings, we start with the Silhouette Score. This measures how well each data point (here, each X-ray embedding) fits within its assigned class (disease label) compared to other classes. A higher score means the embeddings form more distinct clusters, which indicates that our SimCLR model is capturing meaningful patterns in the images."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "# Only consider the disease labels as clusters (ignore 'No Finding' if desired)\n",
    "# Convert multi-label to single-label by taking argmax for simplicity\n",
    "chexpert_val_single_label = np.argmax(chexpert_val_labels, axis=1)\n",
    "\n",
    "# Compute silhouette score\n",
    "sil_score_chexpert = silhouette_score(emb_chexpert.numpy(), chexpert_val_single_label)\n",
    "print(f\"Silhouette Score (CheXpert embeddings): {sil_score_chexpert:.4f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "# Only consider the disease labels as clusters (ignore 'No Finding' if desired)\n",
    "# Convert multi-label to single-label by taking argmax for simplicity\n",
    "MIMIC_val_single_label = np.argmax(mimic_val_labels, axis=1)\n",
    "\n",
    "# Compute silhouette score\n",
    "sil_score_MIMIC = silhouette_score(emb_mimic.numpy(), MIMIC_val_single_label)\n",
    "print(f\"Silhouette Score (MIMIC embeddings): {sil_score_MIMIC:.4f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To quantitatively evaluate the quality of our SimCLR embeddings, we can use a K-Nearest Neighbor (KNN) classifier.\n",
    "The idea is simple: if the embeddings are meaningful, images with the same label should be closer together in embedding space, so a KNN should classify them reasonably well.\n",
    "This gives a practical, label-based measure of how well the self-supervised embeddings capture relevant structure in the data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use a simple KNN on embeddings\n",
    "def knn_eval(embeddings, labels, k=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings, labels)\n",
    "    preds = knn.predict(embeddings)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return acc\n",
    "\n",
    "# CheXpert\n",
    "chexpert_labels = df_valid_chexpert.select([\n",
    "    'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "    'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "    'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices'\n",
    "]).to_numpy()\n",
    "\n",
    "# Convert one-hot / multi-label to single class for simplicity (e.g., argmax)\n",
    "chexpert_labels_class = chexpert_labels.argmax(axis=1)\n",
    "\n",
    "chexpert_knn_acc = knn_eval(emb_chexpert.numpy(), chexpert_labels_class)\n",
    "print(\"CheXpert KNN accuracy on embeddings:\", chexpert_knn_acc)\n",
    "\n",
    "# MIMIC\n",
    "mimic_labels = df_valid_mimic.select([\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "    'Enlarged Cardiomediastinum', 'Lung Lesion', 'Lung Opacity', 'Normal',\n",
    "    'Pleural Effusion', 'Pneumonia', 'Pneumothorax'\n",
    "]).to_numpy()\n",
    "mimic_labels_class = mimic_labels.argmax(axis=1)\n",
    "\n",
    "mimic_knn_acc = knn_eval(emb_mimic.numpy(), mimic_labels_class)\n",
    "print(\"MIMIC KNN accuracy on embeddings:\", mimic_knn_acc)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ---- 1. Extract Pneumonia labels for both datasets ----\n",
    "labels_chex = df_valid_chexpert[\"Pneumonia\"].fill_null(-1).to_numpy()\n",
    "labels_mimic = df_valid_mimic[\"Pneumonia\"].fill_null(-1).to_numpy()\n",
    "\n",
    "emb_chex_np = emb_chexpert.cpu().numpy()\n",
    "emb_mimic_np = emb_mimic.cpu().numpy()\n",
    "\n",
    "# ---- 2. Combine embeddings for joint t-SNE projection ----\n",
    "emb_combined = np.vstack([emb_chex_np, emb_mimic_np])\n",
    "\n",
    "# Create dataset ID array to distinguish colors:\n",
    "dataset_id = np.array([0]*len(emb_chex_np) + [1]*len(emb_mimic_np))\n",
    "\n",
    "# ---- 3. Run t-SNE on the combined dataset ----\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "emb_2d = tsne.fit_transform(emb_combined)\n",
    "\n",
    "# Split back the projected points\n",
    "chex_points = emb_2d[:len(emb_chex_np)]\n",
    "mimic_points = emb_2d[len(emb_chex_np):]\n",
    "\n",
    "# ---- 4. Plot (side-by-side comparison on SAME 2D space) ----\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.scatter(\n",
    "    chex_points[:,0], chex_points[:,1],\n",
    "    c=labels_chex,\n",
    "    cmap=\"coolwarm\",\n",
    "    s=10,\n",
    "    alpha=0.7,\n",
    "    label=\"CheXpert\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    mimic_points[:,0], mimic_points[:,1],\n",
    "    c=labels_mimic,\n",
    "    cmap=\"coolwarm\",\n",
    "    s=10,\n",
    "    alpha=0.7,\n",
    "    marker='x',\n",
    "    label=\"MIMIC\"\n",
    ")\n",
    "\n",
    "plt.title(\"Pneumonia Distribution in Embedding Space (CheXpert vs MIMIC)\")\n",
    "plt.colorbar(label=\"Pneumonia Label (-1 = uncertain, 0 = negative, 1 = positive)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1. Get pneumonia labels\n",
    "# -------------------------\n",
    "labels_chex = df_valid_chexpert[\"Pneumonia\"].fill_null(-1).to_numpy()\n",
    "labels_mimic = df_valid_mimic[\"Pneumonia\"].fill_null(-1).to_numpy()\n",
    "\n",
    "emb_chex_np = emb_chexpert.cpu().numpy()\n",
    "emb_mimic_np = emb_mimic.cpu().numpy()\n",
    "\n",
    "# -------------------------\n",
    "# 2. Filter to pneumonia only\n",
    "# -------------------------\n",
    "chex_mask = labels_chex == 1\n",
    "mimic_mask = labels_mimic == 1\n",
    "\n",
    "chex_pneu_emb = emb_chex_np[chex_mask]\n",
    "mimic_pneu_emb = emb_mimic_np[mimic_mask]\n",
    "\n",
    "print(\"CheXpert pneumonia cases:\", chex_pneu_emb.shape[0])\n",
    "print(\"MIMIC pneumonia cases:\", mimic_pneu_emb.shape[0])\n",
    "\n",
    "# -------------------------\n",
    "# 3. Combine embeddings for t-SNE\n",
    "# -------------------------\n",
    "combined = np.vstack([chex_pneu_emb, mimic_pneu_emb])\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "combined_2d = tsne.fit_transform(combined)\n",
    "\n",
    "n_chex = chex_pneu_emb.shape[0]\n",
    "\n",
    "chex_2d = combined_2d[:n_chex]\n",
    "mimic_2d = combined_2d[n_chex:]\n",
    "\n",
    "# -------------------------\n",
    "# 4. Plot (only pneumonia points)\n",
    "# -------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    chex_2d[:, 0], chex_2d[:, 1],\n",
    "    s=12, alpha=0.7, label=\"CheXpert Pneumonia\", color=\"blue\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    mimic_2d[:, 0], mimic_2d[:, 1],\n",
    "    s=12, alpha=0.7, label=\"MIMIC Pneumonia\", color=\"red\"\n",
    ")\n",
    "\n",
    "plt.title(\"Pneumonia Embeddings: CheXpert vs MIMIC (Only Pneumonia Points)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert embeddings to numpy\n",
    "emb_chex_np = emb_chexpert.cpu().numpy()\n",
    "emb_mimic_np = emb_mimic.cpu().numpy()\n",
    "\n",
    "# Combine embeddings to fit PCA together\n",
    "all_emb = np.concatenate([emb_chex_np, emb_mimic_np], axis=0)\n",
    "\n",
    "# Fit PCA to reduce to 2 components\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "all_emb_2d = pca.fit_transform(all_emb)\n",
    "\n",
    "# Split transformed embeddings back\n",
    "chex_2d = all_emb_2d[:len(emb_chex_np)]\n",
    "mimic_2d = all_emb_2d[len(emb_chex_np):]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(chex_2d[:,0], chex_2d[:,1], s=10, alpha=0.7, label=\"CheXpert\", color=\"blue\")\n",
    "plt.scatter(mimic_2d[:,0], mimic_2d[:,1], s=10, alpha=0.7, label=\"MIMIC\", color=\"red\")\n",
    "plt.title(\"PCA of CheXpert vs MIMIC embeddings\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Optional: variance explained\n",
    "explained = pca.explained_variance_ratio_\n",
    "print(f\"Variance explained by PC1 and PC2: {explained[0]:.3f}, {explained[1]:.3f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PCA of CheXpert & MIMIC Embeddings\n",
    "\n",
    "**What this test does:**\n",
    "- PCA reduces high-dimensional embeddings (128D) to 2D for visualization.\n",
    "- Each point represents a single chest X-ray image, projected into a plane capturing the main variance in the data.\n",
    "- Coloring by Pneumonia label lets us see whether images with the disease cluster together, and if the clusters differ between datasets.\n",
    "\n",
    "**Why it’s relevant:**\n",
    "- By comparing CheXpert and MIMIC in the **same embedding space**, we can evaluate **dataset similarity and domain shifts**.\n",
    "- If pneumonia cases cluster together across both datasets, it indicates the model has learned disease-relevant features that generalize.\n",
    "- Differences in cluster tightness or overlap may suggest **dataset-specific biases** or **labeling inconsistencies**, which are critical for downstream model performance.\n",
    "\n",
    "**Insights we can gain:**\n",
    "- How well the SimCLR embeddings separate diseased vs healthy cases.\n",
    "- Differences in disease representation across CheXpert and MIMIC.\n",
    "- Whether embeddings are suitable for cross-dataset tasks like transfer learning.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# -------------------------\n",
    "# 1. Extract labels for Pneumonia (Polars)\n",
    "# -------------------------\n",
    "labels_chex = df_valid_chexpert.select(\"Pneumonia\").to_numpy().flatten()\n",
    "labels_mimic = df_valid_mimic.select(\"Pneumonia\").to_numpy().flatten()\n",
    "\n",
    "# Filter out missing labels (-1)\n",
    "chex_mask = labels_chex != -1\n",
    "mimic_mask = labels_mimic != -1\n",
    "\n",
    "emb_chex_np = emb_chexpert.cpu().numpy()[chex_mask]\n",
    "emb_mimic_np = emb_mimic.cpu().numpy()[mimic_mask]\n",
    "\n",
    "labels_chex = labels_chex[chex_mask]\n",
    "labels_mimic = labels_mimic[mimic_mask]\n",
    "\n",
    "# -------------------------\n",
    "# 2. Combine embeddings and run PCA\n",
    "# -------------------------\n",
    "combined_emb = np.vstack([emb_chex_np, emb_mimic_np])\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_emb = pca.fit_transform(combined_emb)\n",
    "\n",
    "# Split back for plotting\n",
    "pca_chex = pca_emb[:len(emb_chex_np)]\n",
    "pca_mimic = pca_emb[len(emb_chex_np):]\n",
    "\n",
    "# -------------------------\n",
    "# 3. Plot PCA colored by Pneumonia\n",
    "# -------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# CheXpert\n",
    "plt.scatter(\n",
    "    pca_chex[labels_chex==0, 0], pca_chex[labels_chex==0, 1],\n",
    "    color='lightblue', label='CheXpert No Pneumonia', alpha=0.5, s=20\n",
    ")\n",
    "plt.scatter(\n",
    "    pca_chex[labels_chex==1, 0], pca_chex[labels_chex==1, 1],\n",
    "    color='blue', label='CheXpert Pneumonia', alpha=0.7, s=20\n",
    ")\n",
    "\n",
    "# MIMIC\n",
    "plt.scatter(\n",
    "    pca_mimic[labels_mimic==0, 0], pca_mimic[labels_mimic==0, 1],\n",
    "    color='lightcoral', label='MIMIC No Pneumonia', alpha=0.5, s=20\n",
    ")\n",
    "plt.scatter(\n",
    "    pca_mimic[labels_mimic==1, 0], pca_mimic[labels_mimic==1, 1],\n",
    "    color='red', label='MIMIC Pneumonia', alpha=0.7, s=20\n",
    ")\n",
    "\n",
    "plt.title(\"PCA of CheXpert & MIMIC embeddings colored by Pneumonia\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## UMAP Visualization of Chest X-ray Embeddings\n",
    "\n",
    "UMAP (Uniform Manifold Approximation and Projection) is a dimensionality reduction technique similar to t-SNE but often preserves more of the global structure of the data. By projecting our high-dimensional embeddings (128-dimensional SimCLR features) down to 2D, we can visualize how the model organizes chest X-ray images.\n",
    "\n",
    "This is relevant because:\n",
    "- It helps us **see if the embeddings naturally cluster according to disease labels**.\n",
    "- It allows **cross-dataset comparisons** (CheXpert vs MIMIC) to assess generalization.\n",
    "- UMAP is faster than t-SNE for larger datasets and can maintain a sense of overall geometry of the data.\n",
    "\n",
    "We will run UMAP on the embeddings of both CheXpert and MIMIC validation sets and plot them on the same figure for comparison.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import umap\n",
    "\n",
    "\n",
    "# ---- 1. Convert embeddings to numpy ----\n",
    "emb_chex_np = emb_chexpert.cpu().numpy()\n",
    "emb_mimic_np = emb_mimic.cpu().numpy()\n",
    "\n",
    "# ---- 2. Fit UMAP on both datasets together for a shared space ----\n",
    "all_emb = np.vstack([emb_chex_np, emb_mimic_np])\n",
    "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "emb_2d = umap_model.fit_transform(all_emb)\n",
    "\n",
    "# ---- 3. Split back to original datasets ----\n",
    "emb_chex_2d = emb_2d[:len(emb_chex_np)]\n",
    "emb_mimic_2d = emb_2d[len(emb_chex_np):]\n",
    "\n",
    "# ---- 4. Plot ----\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(emb_chex_2d[:, 0], emb_chex_2d[:, 1], s=10, alpha=0.7, label='CheXpert', color='blue')\n",
    "plt.scatter(emb_mimic_2d[:, 0], emb_mimic_2d[:, 1], s=10, alpha=0.7, label='MIMIC', color='red')\n",
    "plt.title(\"UMAP of Chest X-ray Embeddings (CheXpert vs MIMIC)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "disease_name = \"Pneumothorax\"  # Change to other diseases as needed\n",
    "\n",
    "labels_chex = df_valid_chexpert[disease_name].fill_null(-1).to_numpy()\n",
    "labels_mimic = df_valid_mimic[disease_name].fill_null(-1).to_numpy()\n",
    "\n",
    "# ---- 2. Mask non-disease points if desired (-1 is treated as missing) ----\n",
    "mask_chex = labels_chex != -1\n",
    "mask_mimic = labels_mimic != -1\n",
    "\n",
    "# ---- 3. Plot UMAP colored by disease ----\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(\n",
    "    emb_chex_2d[mask_chex, 0], emb_chex_2d[mask_chex, 1],\n",
    "    c=labels_chex[mask_chex], cmap=\"coolwarm\", s=15, alpha=0.7, label=\"CheXpert\"\n",
    ")\n",
    "plt.scatter(\n",
    "    emb_mimic_2d[mask_mimic, 0], emb_mimic_2d[mask_mimic, 1],\n",
    "    c=labels_mimic[mask_mimic], cmap=\"coolwarm\", s=15, alpha=0.7, marker='x', label=\"MIMIC\"\n",
    ")\n",
    "plt.colorbar(label=disease_name)\n",
    "plt.title(f\"UMAP of {disease_name} Embeddings (CheXpert vs MIMIC)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross-Dataset KNN Evaluation\n",
    "\n",
    "We want to test **how well the features learned by SimCLR on one dataset generalize to another dataset**.\n",
    "\n",
    "Steps:\n",
    "1. Train a simple K-Nearest Neighbors (KNN) classifier using embeddings from CheXpert and their labels.\n",
    "2. Test the classifier on MIMIC embeddings (and vice versa).\n",
    "3. Compute accuracy or F1-score.\n",
    "\n",
    "Interpretation:\n",
    "- High cross-dataset accuracy → embeddings capture **generalizable clinical features**.\n",
    "- Low cross-dataset accuracy → embeddings are **dataset-specific**, possibly due to domain differences in image acquisition or labeling.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "# ---- 1. Select disease for cross-examination ----\n",
    "disease_name = \"Pneumonia\"\n",
    "\n",
    "# ---- 2. Get labels (Polars to NumPy) ----\n",
    "labels_chex = df_valid_chexpert[disease_name].fill_null(-1).to_numpy()\n",
    "labels_mimic = df_valid_mimic[disease_name].fill_null(-1).to_numpy()\n",
    "\n",
    "# Mask out missing labels\n",
    "mask_chex = labels_chex != -1\n",
    "mask_mimic = labels_mimic != -1\n",
    "\n",
    "X_train = emb_chexpert.cpu().numpy()[mask_chex]\n",
    "y_train = labels_chex[mask_chex]\n",
    "\n",
    "X_test = emb_mimic.cpu().numpy()[mask_mimic]\n",
    "y_test = labels_mimic[mask_mimic]\n",
    "\n",
    "# ---- 3. Train KNN on CheXpert and test on MIMIC ----\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Cross-Dataset KNN (CheXpert -> MIMIC) Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Cross-Dataset KNN (CheXpert -> MIMIC) F1-score: {f1:.3f}\")\n",
    "\n",
    "# ---- Optional: Reverse (MIMIC -> CheXpert) ----\n",
    "X_train_rev = emb_mimic.cpu().numpy()[mask_mimic]\n",
    "y_train_rev = labels_mimic[mask_mimic]\n",
    "\n",
    "X_test_rev = emb_chexpert.cpu().numpy()[mask_chex]\n",
    "y_test_rev = labels_chex[mask_chex]\n",
    "\n",
    "knn_rev = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_rev.fit(X_train_rev, y_train_rev)\n",
    "y_pred_rev = knn_rev.predict(X_test_rev)\n",
    "\n",
    "accuracy_rev = accuracy_score(y_test_rev, y_pred_rev)\n",
    "f1_rev = f1_score(y_test_rev, y_pred_rev)\n",
    "\n",
    "print(f\"Cross-Dataset KNN (MIMIC -> CheXpert) Accuracy: {accuracy_rev:.3f}\")\n",
    "print(f\"Cross-Dataset KNN (MIMIC -> CheXpert) F1-score: {f1_rev:.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cross-Dataset AUROC Evaluation\n",
    "\n",
    "**Objective:**\n",
    "Assess how well embeddings learned from one dataset (CheXpert or MIMIC) generalize to the other using AUROC (Area Under the Receiver Operating Characteristic curve).\n",
    "\n",
    "**Why AUROC:**\n",
    "- Measures the ability to distinguish positive (disease) vs. negative (no disease) cases.\n",
    "- Robust to class imbalance, which is common in medical datasets like Pneumonia.\n",
    "- Higher AUROC indicates embeddings capture meaningful disease-specific features that transfer across datasets.\n",
    "\n",
    "**Method:**\n",
    "1. Extract embeddings for the validation sets of both datasets.\n",
    "2. Train a logistic regression classifier on one dataset’s embeddings and labels.\n",
    "3. Test the classifier on the other dataset’s embeddings.\n",
    "4. Compute AUROC to quantify how well the learned embeddings generalize.\n",
    "\n",
    "**Interpretation:**\n",
    "- **High AUROC** → Features learned on the source dataset generalize well; disease patterns are captured effectively.\n",
    "- **Low AUROC** → Embeddings may be dataset-specific or missing key disease features; indicates areas for further research or improvement.\n",
    "\n",
    "This analysis helps us evaluate **cross-dataset robustness** of self-supervised embeddings, which is crucial for clinical applications where data distribution varies across hospitals or populations.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ---- 1. Select disease for cross-examination ----\n",
    "disease_name = \"Pneumonia\"\n",
    "\n",
    "# ---- 2. Get labels (Polars to NumPy) ----\n",
    "labels_chex = df_valid_chexpert[disease_name].fill_null(-1).to_numpy()\n",
    "labels_mimic = df_valid_mimic[disease_name].fill_null(-1).to_numpy()\n",
    "\n",
    "\n",
    "# ---- 2. Convert embeddings to numpy ----\n",
    "emb_chex_np = emb_chexpert.cpu().numpy()\n",
    "emb_mimic_np = emb_mimic.cpu().numpy()\n",
    "\n",
    "# ---- 3. Train simple logistic regression on one dataset, test on the other ----\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# CheXpert -> MIMIC\n",
    "clf_chex = LogisticRegression(max_iter=1000)\n",
    "clf_chex.fit(emb_chex_np, labels_chex)\n",
    "pred_probs_mimic = clf_chex.predict_proba(emb_mimic_np)[:, 1]  # probability of positive class\n",
    "auroc_chex2mimic = roc_auc_score(labels_mimic, pred_probs_mimic)\n",
    "\n",
    "# MIMIC -> CheXpert\n",
    "clf_mim = LogisticRegression(max_iter=1000)\n",
    "clf_mim.fit(emb_mimic_np, labels_mimic)\n",
    "pred_probs_chex = clf_mim.predict_proba(emb_chex_np)[:, 1]\n",
    "auroc_mim2chex = roc_auc_score(labels_chex, pred_probs_chex)\n",
    "\n",
    "print(f\"Cross-Dataset AUROC (CheXpert -> MIMIC): {auroc_chex2mimic:.3f}\")\n",
    "print(f\"Cross-Dataset AUROC (MIMIC -> CheXpert): {auroc_mim2chex:.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary of Embedding Evaluation Tests\n",
    "\n",
    "| Test | What it Measures | Why it is Relevant | Typical Expectations / Notes |\n",
    "|------|-----------------|-----------------|-----------------------------|\n",
    "| **t-SNE / UMAP** | Visual clustering of embeddings in 2D | Helps us see if images with similar features (or disease labels) naturally group together | Clusters should form for similar disease cases; overlapping clusters indicate embeddings are less discriminative |\n",
    "| **Silhouette Score** | How well each point fits within its cluster | Quantifies clustering quality numerically | Score ranges from -1 to 1; closer to 1 = tight, well-separated clusters; negative = poor separation |\n",
    "| **K-Nearest Neighbors (KNN)** | Classification accuracy using nearest neighbors in embedding space | Tests whether embeddings capture disease information that can predict labels | High accuracy (>70%) shows embeddings encode meaningful disease patterns; low accuracy suggests weak embeddings |\n",
    "| **Cross-Dataset KNN** | KNN accuracy when training on one dataset and testing on another | Measures generalization of embeddings across datasets | High accuracy indicates good transferability; low accuracy indicates dataset-specific features dominate |\n",
    "| **AUROC (Area Under ROC Curve)** | Ability of embeddings to rank positive vs. negative cases | Standard for binary classification performance; insensitive to class imbalance | Values range 0–1; 0.5 = random, >0.7 is reasonable, >0.9 is excellent. AUROC near 0.5 for cross-dataset means poor generalization |\n",
    "| **PCA Explained Variance** | How much of the embedding variance is captured by the principal components | Helps identify dominant patterns in the embeddings and dimensionality reduction | Usually first 2–3 PCs capture meaningful variance; low variance explained may suggest complex or noisy embeddings |\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPk3VYQAvkG8XZbveKPAqcC",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
