{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ccorbett0116/Fall2025ResearchProject/blob/main/Research_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVMwQDnKO8XY"
   },
   "source": [
    "# Project Title:\n",
    "# Authors: Jose Henriquez, Cole Corbett\n",
    "## Description:\n",
    "The deployment of medical AI systems across different hospitals raises critical questions about whether fairness and representation quality can be reliably transferred across clinical domains. Models trained on one hospital’s imaging data are often reused in new environments where patient demographics, imaging devices, and diagnostic practices differ substantially, potentially resulting in unintended bias against certain groups. This project investigates this challenge by studying fairness-aware representation alignment in medical imaging. The student will train contrastive learning models—such as SimCLR—independently on two large-scale chest X-ray datasets: CheXpert (from Stanford Hospital) and MIMIC-CXR (from Beth Israel Deaconess Medical Center). After learning embeddings in each domain, the student will apply domain alignment techniques such as Procrustes alignment to map representations from the CheXpert embedding space into the MIMIC-CXR space. The aligned embeddings will then be evaluated using fairness metrics designed for representation spaces, including demographic subgroup alignment, intra- vs. inter-group embedding disparity, and cluster-level demographic parity. The expected outcome is a rigorous understanding of whether fairness properties learned in one hospital setting preserve, degrade, or improve when transferred to another, revealing how robust model fairness is to realworld clinical domain shifts. A practical use case involves a healthcare network seeking to deploy a model trained at a major academic hospital (e.g., Stanford) into a community hospital setting: this project helps determine whether the transferred representations remain equitable across patient groups such as older adults, women, or specific disease cohorts. The findings will support responsible AI deployment in healthcare by highlighting the conditions under which fairness is stable across institutions and identifying scenarios where domain-specific mitigation strategies may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T22:40:57.226897Z",
     "start_time": "2025-11-17T22:40:46.108146Z"
    },
    "id": "uhUKfIU5G_5u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Users\\joseh\\Desktop\\Masters' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Process is probably different on colab, this is hyperspecific to me because I'm working on Pycharm connected to my WSL\n",
    "import sys\n",
    "!{sys.executable} -m pip install kagglehub polars\n",
    "#We're going to use polars because it's significantly faster, it's build on rust and enables multi-threaded processing as well as some memory optimizations over pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:02:52.542252Z",
     "start_time": "2025-11-17T23:02:52.164261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to chexpert dataset files: C:\\Users\\joseh\\.cache\\kagglehub\\datasets\\mimsadiislam\\chexpert\\versions\\1\n",
      "Path to mimic dataset files: C:\\Users\\joseh\\.cache\\kagglehub\\datasets\\simhadrisadaram\\mimic-cxr-dataset\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Again, this is probably different on colab\n",
    "import kagglehub\n",
    "path_chexpert = kagglehub.dataset_download(\"mimsadiislam/chexpert\")\n",
    "print(\"Path to chexpert dataset files:\", path_chexpert)\n",
    "path_mimic = kagglehub.dataset_download(\"simhadrisadaram/mimic-cxr-dataset\")\n",
    "print(\"Path to mimic dataset files:\", path_mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:03:33.697687Z",
     "start_time": "2025-11-17T23:03:33.694832Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.listdir(path_mimic)\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"./embeddings\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:06:02.171042Z",
     "start_time": "2025-11-17T23:06:02.117046Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "dir_chexpert = os.path.join(path_chexpert, \"CheXpert-v1.0-small\")\n",
    "dir_mimic = path_mimic\n",
    "\n",
    "train_csv_chexpert = os.path.join(dir_chexpert, \"train.csv\")\n",
    "train_csv_mimic = os.path.join(dir_mimic, \"mimic_cxr_aug_train.csv\")\n",
    "valid_csv_chexpert = os.path.join(dir_chexpert, \"valid.csv\")\n",
    "valid_csv_mimic = os.path.join(dir_mimic, \"mimic_cxr_aug_validate.csv\")\n",
    "\n",
    "df_train_chexpert = pl.read_csv(train_csv_chexpert)\n",
    "df_train_mimic = pl.read_csv(train_csv_mimic)\n",
    "df_valid_chexpert = pl.read_csv(valid_csv_chexpert)\n",
    "df_valid_mimic = pl.read_csv(valid_csv_mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:06:04.059255Z",
     "start_time": "2025-11-17T23:06:04.055880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Path</th><th>Sex</th><th>Age</th><th>Frontal/Lateral</th><th>AP/PA</th><th>No Finding</th><th>Enlarged Cardiomediastinum</th><th>Cardiomegaly</th><th>Lung Opacity</th><th>Lung Lesion</th><th>Edema</th><th>Consolidation</th><th>Pneumonia</th><th>Atelectasis</th><th>Pneumothorax</th><th>Pleural Effusion</th><th>Pleural Other</th><th>Fracture</th><th>Support Devices</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>68</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>87</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>null</td><td>null</td><td>-1.0</td><td>1.0</td><td>null</td><td>-1.0</td><td>-1.0</td><td>null</td><td>-1.0</td><td>null</td><td>-1.0</td><td>null</td><td>1.0</td><td>null</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>83</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>-1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>83</td><td>&quot;Lateral&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>-1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Male&quot;</td><td>41</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "┌──────────────────┬────────┬─────┬──────────────────┬───┬──────────┬─────────┬──────────┬─────────┐\n",
       "│ Path             ┆ Sex    ┆ Age ┆ Frontal/Lateral  ┆ … ┆ Pleural  ┆ Pleural ┆ Fracture ┆ Support │\n",
       "│ ---              ┆ ---    ┆ --- ┆ ---              ┆   ┆ Effusion ┆ Other   ┆ ---      ┆ Devices │\n",
       "│ str              ┆ str    ┆ i64 ┆ str              ┆   ┆ ---      ┆ ---     ┆ f64      ┆ ---     │\n",
       "│                  ┆        ┆     ┆                  ┆   ┆ f64      ┆ f64     ┆          ┆ f64     │\n",
       "╞══════════════════╪════════╪═════╪══════════════════╪═══╪══════════╪═════════╪══════════╪═════════╡\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 68  ┆ Frontal          ┆ … ┆ null     ┆ null    ┆ null     ┆ 1.0     │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 87  ┆ Frontal          ┆ … ┆ -1.0     ┆ null    ┆ 1.0      ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 83  ┆ Frontal          ┆ … ┆ null     ┆ null    ┆ 1.0      ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 83  ┆ Lateral          ┆ … ┆ null     ┆ null    ┆ 1.0      ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Male   ┆ 41  ┆ Frontal          ┆ … ┆ null     ┆ null    ┆ null     ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "└──────────────────┴────────┴─────┴──────────────────┴───┴──────────┴─────────┴──────────┴─────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_chexpert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:06:08.544149Z",
     "start_time": "2025-11-17T23:06:08.540252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Unnamed: 0.1</th><th>Unnamed: 0</th><th>subject_id</th><th>image</th><th>view</th><th>AP</th><th>PA</th><th>Lateral</th><th>text</th><th>text_augment</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>10000032</td><td>&quot;[&#x27;files/p10/p10000032/s5041426…</td><td>&quot;[&#x27;PA&#x27;, &#x27;LATERAL&#x27;, &#x27;AP&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000032/s5391176…</td><td>&quot;[&#x27;files/p10/p10000032/s5041426…</td><td>&quot;[&#x27;files/p10/p10000032/s5041426…</td><td>&quot;[&#x27;Findings: There is no focal …</td><td>&quot;[&#x27;Findings: There is no focus,…</td></tr><tr><td>1</td><td>1</td><td>10000764</td><td>&quot;[&#x27;files/p10/p10000764/s5737596…</td><td>&quot;[&#x27;AP&#x27;, &#x27;LATERAL&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000764/s5737596…</td><td>&quot;[]&quot;</td><td>&quot;[&#x27;files/p10/p10000764/s5737596…</td><td>&quot;[&#x27;Findings: PA and lateral vie…</td><td>&quot;[&#x27;Finds: PA and lateral view o…</td></tr><tr><td>2</td><td>2</td><td>10000898</td><td>&quot;[&#x27;files/p10/p10000898/s5077138…</td><td>&quot;[&#x27;LATERAL&#x27;, &#x27;PA&#x27;]&quot;</td><td>&quot;[]&quot;</td><td>&quot;[&#x27;files/p10/p10000898/s5077138…</td><td>&quot;[&#x27;files/p10/p10000898/s5077138…</td><td>&quot;[&#x27;Findings: PA and lateral vie…</td><td>&quot;[&#x27;Finds: PA and side view of t…</td></tr><tr><td>3</td><td>3</td><td>10000935</td><td>&quot;[&#x27;files/p10/p10000935/s5057897…</td><td>&quot;[&#x27;AP&#x27;, &#x27;LATERAL&#x27;, &#x27;LL&#x27;, &#x27;PA&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000935/s5057897…</td><td>&quot;[&#x27;files/p10/p10000935/s5569729…</td><td>&quot;[&#x27;files/p10/p10000935/s5117837…</td><td>&quot;[&#x27;Findings: Lung volumes remai…</td><td>&quot;[&#x27;Results: Pulmonary volumes r…</td></tr><tr><td>4</td><td>4</td><td>10000980</td><td>&quot;[&#x27;files/p10/p10000980/s5098509…</td><td>&quot;[&#x27;PA&#x27;, &#x27;LL&#x27;, &#x27;AP&#x27;, &#x27;LATERAL&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000980/s5196728…</td><td>&quot;[&#x27;files/p10/p10000980/s5098509…</td><td>&quot;[&#x27;files/p10/p10000980/s5457736…</td><td>&quot;[&#x27;Findings:&nbsp;&nbsp;Impression: Compa…</td><td>&quot;[&#x27;Findings: Impression: Compar…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ Unnamed:  ┆ Unnamed:  ┆ subject_i ┆ image     ┆ … ┆ PA        ┆ Lateral   ┆ text      ┆ text_aug │\n",
       "│ 0.1       ┆ 0         ┆ d         ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ment     │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ str       ┆   ┆ str       ┆ str       ┆ str       ┆ ---      │\n",
       "│ i64       ┆ i64       ┆ i64       ┆           ┆   ┆           ┆           ┆           ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0         ┆ 0         ┆ 10000032  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Findin │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s: There  ┆ gs:      │\n",
       "│           ┆           ┆           ┆ 032/s5041 ┆   ┆ 032/s5041 ┆ 032/s5041 ┆ is no     ┆ There is │\n",
       "│           ┆           ┆           ┆ 426…      ┆   ┆ 426…      ┆ 426…      ┆ focal …   ┆ no       │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ focus,…  │\n",
       "│ 1         ┆ 1         ┆ 10000764  ┆ ['files/p ┆ … ┆ []        ┆ ['files/p ┆ ['Finding ┆ ['Finds: │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆           ┆ 10/p10000 ┆ s: PA and ┆ PA and   │\n",
       "│           ┆           ┆           ┆ 764/s5737 ┆   ┆           ┆ 764/s5737 ┆ lateral   ┆ lateral  │\n",
       "│           ┆           ┆           ┆ 596…      ┆   ┆           ┆ 596…      ┆ vie…      ┆ view o…  │\n",
       "│ 2         ┆ 2         ┆ 10000898  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Finds: │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s: PA and ┆ PA and   │\n",
       "│           ┆           ┆           ┆ 898/s5077 ┆   ┆ 898/s5077 ┆ 898/s5077 ┆ lateral   ┆ side     │\n",
       "│           ┆           ┆           ┆ 138…      ┆   ┆ 138…      ┆ 138…      ┆ vie…      ┆ view of  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ t…       │\n",
       "│ 3         ┆ 3         ┆ 10000935  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Result │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s: Lung   ┆ s: Pulmo │\n",
       "│           ┆           ┆           ┆ 935/s5057 ┆   ┆ 935/s5569 ┆ 935/s5117 ┆ volumes   ┆ nary     │\n",
       "│           ┆           ┆           ┆ 897…      ┆   ┆ 729…      ┆ 837…      ┆ remai…    ┆ volumes  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ r…       │\n",
       "│ 4         ┆ 4         ┆ 10000980  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Findin │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s:  Impre ┆ gs: Impr │\n",
       "│           ┆           ┆           ┆ 980/s5098 ┆   ┆ 980/s5098 ┆ 980/s5457 ┆ ssion:    ┆ ession:  │\n",
       "│           ┆           ┆           ┆ 509…      ┆   ┆ 509…      ┆ 736…      ┆ Compa…    ┆ Compar…  │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_mimic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joseh\\desktop\\masters  work\\blessings work\\fall2025researchproject\\simclr_env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# Medical-safe augmentations for SimCLR\n",
    "simclr_aug = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.GaussianBlur(3),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "class XRaySimCLRDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Polars returns a Row object\n",
    "        row = self.df[idx]\n",
    "        img_path = os.path.join(self.root_dir, row[\"Path\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            # Return two augmented views\n",
    "            return self.transform(img), self.transform(img)\n",
    "        else:\n",
    "            return img, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataloader \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset_chexpert = XRaySimCLRDataset(df_train_chexpert, dir_chexpert, simclr_aug)\n",
    "train_loader_chexpert = DataLoader(train_dataset_chexpert, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "train_dataset_mimic = XRaySimCLRDataset(df_train_mimic, dir_mimic, simclr_aug)\n",
    "train_loader_mimic = DataLoader(train_dataset_mimic, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=2048, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, out_dim=128):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights=None)\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.projector = ProjectionHead(2048, 2048, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).squeeze()\n",
    "        z = self.projector(h)\n",
    "        return h, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(z, temperature=0.5):\n",
    "    z = F.normalize(z, dim=1)\n",
    "    similarity_matrix = torch.matmul(z, z.T)\n",
    "    logits = similarity_matrix / temperature\n",
    "    labels = torch.arange(z.size(0)).to(z.device)\n",
    "    return F.cross_entropy(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CheXpert Dataset training loop\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimCLR().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 10  # adjust for full training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x1, x2 in train_loader_chexpert:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, z1 = model(x1)\n",
    "        _, z2 = model(x2)\n",
    "\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        loss = nt_xent_loss(z)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(model.state_dict(), \"./checkpoints/simclr_chexpert.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIMIC Dataset training loop\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimCLR().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 10  # adjust for full training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x1, x2 in train_loader_mimic:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, z1 = model(x1)\n",
    "        _, z2 = model(x2)\n",
    "\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        loss = nt_xent_loss(z)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(model.state_dict(), \"/checkpoints/simclr_mimic.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for x1, _ in loader:\n",
    "            x1 = x1.to(device)\n",
    "            h, _ = model(x1)\n",
    "            embeddings.append(h.cpu())\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "emb_chexpert = extract_embeddings(model, train_loader_chexpert)\n",
    "torch.save(emb_chexpert, \"/embeddings/chexpert.pt\")\n",
    "emb_mimic = extract_embeddings(model, train_loader_mimic, device=\"cuda\")\n",
    "torch.save(emb_mimic, \"./embeddings/mimic.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes_alignment(X, Y):\n",
    "    U, _, Vt = torch.linalg.svd(Y.T @ X)\n",
    "    R = U @ Vt\n",
    "    X_aligned = X @ R.T\n",
    "    return X_aligned\n",
    "\n",
    "aligned_chexpert = procrustes_alignment(emb_chexpert, emb_mimic)\n",
    "torch.save(aligned_chexpert, \"/embeddings/chexpert_aligned.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_centroid_distance_pl(embeddings, demographics):\n",
    "    # Convert to a list of unique groups\n",
    "    groups = demographics.unique().to_list()  # Polars syntax\n",
    "    centroids = {}\n",
    "\n",
    "    for g in groups:\n",
    "        # Filter embeddings by group\n",
    "        idxs = [i for i, val in enumerate(demographics) if val == g]\n",
    "        group_emb = embeddings[idxs]\n",
    "        centroids[g] = group_emb.mean(dim=0)\n",
    "\n",
    "    dist = {}\n",
    "    for g1 in groups:\n",
    "        for g2 in groups:\n",
    "            dist[(g1, g2)] = torch.norm(centroids[g1] - centroids[g2]).item()\n",
    "    return dist\n",
    "\n",
    "df_demo = pl.read_csv(os.path.join(dir_chexpert, \"demographics.csv\"))\n",
    "# Assume 'Sex' column exists\n",
    "demographics = df_demo[\"Sex\"].to_list()  # Polars column → Python list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_centroid_distance(embeddings, demographics):\n",
    "    groups = demographics.unique()\n",
    "    centroids = {g: embeddings[demographics==g].mean(dim=0) for g in groups}\n",
    "    dist = {}\n",
    "    for g1 in groups:\n",
    "        for g2 in groups:\n",
    "            dist[(g1,g2)] = torch.norm(centroids[g1] - centroids[g2]).item()\n",
    "    return dist\n",
    "\n",
    "import pandas as pd\n",
    "df_demo = pd.read_csv(os.path.join(dir_chexpert, \"demographics.csv\"))  # must contain 'Sex' column\n",
    "distances = subgroup_centroid_distance(aligned_chexpert, df_demo[\"Sex\"])\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPk3VYQAvkG8XZbveKPAqcC",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "simclr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
