{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ccorbett0116/Fall2025ResearchProject/blob/main/Research_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVMwQDnKO8XY"
   },
   "source": [
    "# Project Title:\n",
    "# Authors: Jose Henriquez, Cole Corbett\n",
    "## Description:\n",
    "The deployment of medical AI systems across different hospitals raises critical questions about whether fairness and representation quality can be reliably transferred across clinical domains. Models trained on one hospital’s imaging data are often reused in new environments where patient demographics, imaging devices, and diagnostic practices differ substantially, potentially resulting in unintended bias against certain groups. This project investigates this challenge by studying fairness-aware representation alignment in medical imaging. The student will train contrastive learning models—such as SimCLR—independently on two large-scale chest X-ray datasets: CheXpert (from Stanford Hospital) and MIMIC-CXR (from Beth Israel Deaconess Medical Center). After learning embeddings in each domain, the student will apply domain alignment techniques such as Procrustes alignment to map representations from the CheXpert embedding space into the MIMIC-CXR space. The aligned embeddings will then be evaluated using fairness metrics designed for representation spaces, including demographic subgroup alignment, intra- vs. inter-group embedding disparity, and cluster-level demographic parity. The expected outcome is a rigorous understanding of whether fairness properties learned in one hospital setting preserve, degrade, or improve when transferred to another, revealing how robust model fairness is to realworld clinical domain shifts. A practical use case involves a healthcare network seeking to deploy a model trained at a major academic hospital (e.g., Stanford) into a community hospital setting: this project helps determine whether the transferred representations remain equitable across patient groups such as older adults, women, or specific disease cohorts. The findings will support responsible AI deployment in healthcare by highlighting the conditions under which fairness is stable across institutions and identifying scenarios where domain-specific mitigation strategies may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T22:40:57.226897Z",
     "start_time": "2025-11-17T22:40:46.108146Z"
    },
    "id": "uhUKfIU5G_5u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting polars\n",
      "  Downloading polars-1.35.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\joseh\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from kagglehub) (4.67.1)\n",
      "Collecting polars-runtime-32==1.35.2 (from polars)\n",
      "  Downloading polars_runtime_32-1.35.2-cp39-abi3-win_amd64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from requests->kagglehub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\joseh\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Downloading polars-1.35.2-py3-none-any.whl (783 kB)\n",
      "   ---------------------------------------- 0.0/783.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 783.6/783.6 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading polars_runtime_32-1.35.2-cp39-abi3-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 11.5/41.3 MB 55.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 31.7/41.3 MB 75.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 66.2 MB/s eta 0:00:00\n",
      "Installing collected packages: polars-runtime-32, polars, kagglehub\n",
      "Successfully installed kagglehub-0.3.13 polars-1.35.2 polars-runtime-32-1.35.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Process is probably different on colab, this is hyperspecific to me because I'm working on Pycharm connected to my WSL\n",
    "import sys\n",
    "!{sys.executable} -m pip install kagglehub polars\n",
    "#We're going to use polars because it's significantly faster, it's build on rust and enables multi-threaded processing as well as some memory optimizations over pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:02:52.542252Z",
     "start_time": "2025-11-17T23:02:52.164261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mimsadiislam/chexpert?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10.7G/10.7G [02:08<00:00, 89.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to chexpert dataset files: C:\\Users\\joseh\\.cache\\kagglehub\\datasets\\mimsadiislam\\chexpert\\versions\\1\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/simhadrisadaram/mimic-cxr-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16.5G/16.5G [03:30<00:00, 84.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to mimic dataset files: C:\\Users\\joseh\\.cache\\kagglehub\\datasets\\simhadrisadaram\\mimic-cxr-dataset\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Again, this is probably different on colab\n",
    "import kagglehub\n",
    "path_chexpert = kagglehub.dataset_download(\"mimsadiislam/chexpert\")\n",
    "print(\"Path to chexpert dataset files:\", path_chexpert)\n",
    "path_mimic = kagglehub.dataset_download(\"simhadrisadaram/mimic-cxr-dataset\")\n",
    "print(\"Path to mimic dataset files:\", path_mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:03:33.697687Z",
     "start_time": "2025-11-17T23:03:33.694832Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(path_mimic)\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"./embeddings\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:06:02.171042Z",
     "start_time": "2025-11-17T23:06:02.117046Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "dir_chexpert = os.path.join(path_chexpert, \"CheXpert-v1.0-small\")\n",
    "dir_mimic = path_mimic\n",
    "\n",
    "train_csv_chexpert = os.path.join(dir_chexpert, \"train.csv\")\n",
    "train_csv_mimic = os.path.join(dir_mimic, \"mimic_cxr_aug_train.csv\")\n",
    "valid_csv_chexpert = os.path.join(dir_chexpert, \"valid.csv\")\n",
    "valid_csv_mimic = os.path.join(dir_mimic, \"mimic_cxr_aug_validate.csv\")\n",
    "\n",
    "df_train_chexpert = pl.read_csv(train_csv_chexpert)\n",
    "df_train_mimic = pl.read_csv(train_csv_mimic)\n",
    "df_valid_chexpert = pl.read_csv(valid_csv_chexpert)\n",
    "df_valid_mimic = pl.read_csv(valid_csv_mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:06:04.059255Z",
     "start_time": "2025-11-17T23:06:04.055880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Path</th><th>Sex</th><th>Age</th><th>Frontal/Lateral</th><th>AP/PA</th><th>No Finding</th><th>Enlarged Cardiomediastinum</th><th>Cardiomegaly</th><th>Lung Opacity</th><th>Lung Lesion</th><th>Edema</th><th>Consolidation</th><th>Pneumonia</th><th>Atelectasis</th><th>Pneumothorax</th><th>Pleural Effusion</th><th>Pleural Other</th><th>Fracture</th><th>Support Devices</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>68</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>87</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>null</td><td>null</td><td>-1.0</td><td>1.0</td><td>null</td><td>-1.0</td><td>-1.0</td><td>null</td><td>-1.0</td><td>null</td><td>-1.0</td><td>null</td><td>1.0</td><td>null</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>83</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>-1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Female&quot;</td><td>83</td><td>&quot;Lateral&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>-1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td></tr><tr><td>&quot;CheXpert-v1.0-small/train/pati…</td><td>&quot;Male&quot;</td><td>41</td><td>&quot;Frontal&quot;</td><td>&quot;AP&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "┌──────────────────┬────────┬─────┬──────────────────┬───┬──────────┬─────────┬──────────┬─────────┐\n",
       "│ Path             ┆ Sex    ┆ Age ┆ Frontal/Lateral  ┆ … ┆ Pleural  ┆ Pleural ┆ Fracture ┆ Support │\n",
       "│ ---              ┆ ---    ┆ --- ┆ ---              ┆   ┆ Effusion ┆ Other   ┆ ---      ┆ Devices │\n",
       "│ str              ┆ str    ┆ i64 ┆ str              ┆   ┆ ---      ┆ ---     ┆ f64      ┆ ---     │\n",
       "│                  ┆        ┆     ┆                  ┆   ┆ f64      ┆ f64     ┆          ┆ f64     │\n",
       "╞══════════════════╪════════╪═════╪══════════════════╪═══╪══════════╪═════════╪══════════╪═════════╡\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 68  ┆ Frontal          ┆ … ┆ null     ┆ null    ┆ null     ┆ 1.0     │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 87  ┆ Frontal          ┆ … ┆ -1.0     ┆ null    ┆ 1.0      ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 83  ┆ Frontal          ┆ … ┆ null     ┆ null    ┆ 1.0      ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Female ┆ 83  ┆ Lateral          ┆ … ┆ null     ┆ null    ┆ 1.0      ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "│ CheXpert-v1.0-sm ┆ Male   ┆ 41  ┆ Frontal          ┆ … ┆ null     ┆ null    ┆ null     ┆ null    │\n",
       "│ all/train/pati…  ┆        ┆     ┆                  ┆   ┆          ┆         ┆          ┆         │\n",
       "└──────────────────┴────────┴─────┴──────────────────┴───┴──────────┴─────────┴──────────┴─────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_chexpert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T23:06:08.544149Z",
     "start_time": "2025-11-17T23:06:08.540252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Unnamed: 0.1</th><th>Unnamed: 0</th><th>subject_id</th><th>image</th><th>view</th><th>AP</th><th>PA</th><th>Lateral</th><th>text</th><th>text_augment</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>10000032</td><td>&quot;[&#x27;files/p10/p10000032/s5041426…</td><td>&quot;[&#x27;PA&#x27;, &#x27;LATERAL&#x27;, &#x27;AP&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000032/s5391176…</td><td>&quot;[&#x27;files/p10/p10000032/s5041426…</td><td>&quot;[&#x27;files/p10/p10000032/s5041426…</td><td>&quot;[&#x27;Findings: There is no focal …</td><td>&quot;[&#x27;Findings: There is no focus,…</td></tr><tr><td>1</td><td>1</td><td>10000764</td><td>&quot;[&#x27;files/p10/p10000764/s5737596…</td><td>&quot;[&#x27;AP&#x27;, &#x27;LATERAL&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000764/s5737596…</td><td>&quot;[]&quot;</td><td>&quot;[&#x27;files/p10/p10000764/s5737596…</td><td>&quot;[&#x27;Findings: PA and lateral vie…</td><td>&quot;[&#x27;Finds: PA and lateral view o…</td></tr><tr><td>2</td><td>2</td><td>10000898</td><td>&quot;[&#x27;files/p10/p10000898/s5077138…</td><td>&quot;[&#x27;LATERAL&#x27;, &#x27;PA&#x27;]&quot;</td><td>&quot;[]&quot;</td><td>&quot;[&#x27;files/p10/p10000898/s5077138…</td><td>&quot;[&#x27;files/p10/p10000898/s5077138…</td><td>&quot;[&#x27;Findings: PA and lateral vie…</td><td>&quot;[&#x27;Finds: PA and side view of t…</td></tr><tr><td>3</td><td>3</td><td>10000935</td><td>&quot;[&#x27;files/p10/p10000935/s5057897…</td><td>&quot;[&#x27;AP&#x27;, &#x27;LATERAL&#x27;, &#x27;LL&#x27;, &#x27;PA&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000935/s5057897…</td><td>&quot;[&#x27;files/p10/p10000935/s5569729…</td><td>&quot;[&#x27;files/p10/p10000935/s5117837…</td><td>&quot;[&#x27;Findings: Lung volumes remai…</td><td>&quot;[&#x27;Results: Pulmonary volumes r…</td></tr><tr><td>4</td><td>4</td><td>10000980</td><td>&quot;[&#x27;files/p10/p10000980/s5098509…</td><td>&quot;[&#x27;PA&#x27;, &#x27;LL&#x27;, &#x27;AP&#x27;, &#x27;LATERAL&#x27;]&quot;</td><td>&quot;[&#x27;files/p10/p10000980/s5196728…</td><td>&quot;[&#x27;files/p10/p10000980/s5098509…</td><td>&quot;[&#x27;files/p10/p10000980/s5457736…</td><td>&quot;[&#x27;Findings:&nbsp;&nbsp;Impression: Compa…</td><td>&quot;[&#x27;Findings: Impression: Compar…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ Unnamed:  ┆ Unnamed:  ┆ subject_i ┆ image     ┆ … ┆ PA        ┆ Lateral   ┆ text      ┆ text_aug │\n",
       "│ 0.1       ┆ 0         ┆ d         ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ment     │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ str       ┆   ┆ str       ┆ str       ┆ str       ┆ ---      │\n",
       "│ i64       ┆ i64       ┆ i64       ┆           ┆   ┆           ┆           ┆           ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0         ┆ 0         ┆ 10000032  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Findin │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s: There  ┆ gs:      │\n",
       "│           ┆           ┆           ┆ 032/s5041 ┆   ┆ 032/s5041 ┆ 032/s5041 ┆ is no     ┆ There is │\n",
       "│           ┆           ┆           ┆ 426…      ┆   ┆ 426…      ┆ 426…      ┆ focal …   ┆ no       │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ focus,…  │\n",
       "│ 1         ┆ 1         ┆ 10000764  ┆ ['files/p ┆ … ┆ []        ┆ ['files/p ┆ ['Finding ┆ ['Finds: │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆           ┆ 10/p10000 ┆ s: PA and ┆ PA and   │\n",
       "│           ┆           ┆           ┆ 764/s5737 ┆   ┆           ┆ 764/s5737 ┆ lateral   ┆ lateral  │\n",
       "│           ┆           ┆           ┆ 596…      ┆   ┆           ┆ 596…      ┆ vie…      ┆ view o…  │\n",
       "│ 2         ┆ 2         ┆ 10000898  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Finds: │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s: PA and ┆ PA and   │\n",
       "│           ┆           ┆           ┆ 898/s5077 ┆   ┆ 898/s5077 ┆ 898/s5077 ┆ lateral   ┆ side     │\n",
       "│           ┆           ┆           ┆ 138…      ┆   ┆ 138…      ┆ 138…      ┆ vie…      ┆ view of  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ t…       │\n",
       "│ 3         ┆ 3         ┆ 10000935  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Result │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s: Lung   ┆ s: Pulmo │\n",
       "│           ┆           ┆           ┆ 935/s5057 ┆   ┆ 935/s5569 ┆ 935/s5117 ┆ volumes   ┆ nary     │\n",
       "│           ┆           ┆           ┆ 897…      ┆   ┆ 729…      ┆ 837…      ┆ remai…    ┆ volumes  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ r…       │\n",
       "│ 4         ┆ 4         ┆ 10000980  ┆ ['files/p ┆ … ┆ ['files/p ┆ ['files/p ┆ ['Finding ┆ ['Findin │\n",
       "│           ┆           ┆           ┆ 10/p10000 ┆   ┆ 10/p10000 ┆ 10/p10000 ┆ s:  Impre ┆ gs: Impr │\n",
       "│           ┆           ┆           ┆ 980/s5098 ┆   ┆ 980/s5098 ┆ 980/s5457 ┆ ssion:    ┆ ession:  │\n",
       "│           ┆           ┆           ┆ 509…      ┆   ┆ 509…      ┆ 736…      ┆ Compa…    ┆ Compar…  │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_mimic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mT\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Medical-safe augmentations for SimCLR\u001b[39;00m\n\u001b[0;32m      8\u001b[0m simclr_aug \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      9\u001b[0m     T\u001b[38;5;241m.\u001b[39mRandomResizedCrop(\u001b[38;5;241m224\u001b[39m, scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)),\n\u001b[0;32m     10\u001b[0m     T\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     T\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     14\u001b[0m ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# Medical-safe augmentations for SimCLR\n",
    "simclr_aug = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.GaussianBlur(3),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "class XRaySimCLRDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Polars returns a Row object\n",
    "        row = self.df[idx]\n",
    "        img_path = os.path.join(self.root_dir, row[\"Path\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            # Return two augmented views\n",
    "            return self.transform(img), self.transform(img)\n",
    "        else:\n",
    "            return img, img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#prepare dataloader \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset_chexpert = XRaySimCLRDataset(df_train_chexpert, dir_chexpert, simclr_aug)\n",
    "train_loader_chexpert = DataLoader(train_dataset_chexpert, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "train_dataset_mimic = XRaySimCLRDataset(df_train_mimic, dir_mimic, simclr_aug)\n",
    "train_loader_mimic = DataLoader(train_dataset_mimic, batch_size=128, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=2048, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, out_dim=128):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights=None)\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.projector = ProjectionHead(2048, 2048, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).squeeze()\n",
    "        z = self.projector(h)\n",
    "        return h, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(z, temperature=0.5):\n",
    "    z = F.normalize(z, dim=1)\n",
    "    similarity_matrix = torch.matmul(z, z.T)\n",
    "    logits = similarity_matrix / temperature\n",
    "    labels = torch.arange(z.size(0)).to(z.device)\n",
    "    return F.cross_entropy(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CheXpert Dataset training loop\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimCLR().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 10  # adjust for full training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x1, x2 in train_loader_chexpert:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, z1 = model(x1)\n",
    "        _, z2 = model(x2)\n",
    "\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        loss = nt_xent_loss(z)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(model.state_dict(), \"./checkpoints/simclr_chexpert.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIMIC Dataset training loop\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimCLR().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 10  # adjust for full training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x1, x2 in train_loader_chexpert:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, z1 = model(x1)\n",
    "        _, z2 = model(x2)\n",
    "\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        loss = nt_xent_loss(z)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(model.state_dict(), \"/checkpoints/simclr_mimic.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for x1, _ in loader:\n",
    "            x1 = x1.to(device)\n",
    "            h, _ = model(x1)\n",
    "            embeddings.append(h.cpu())\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "emb_chexpert = extract_embeddings(model, train_loader_chexpert)\n",
    "torch.save(emb_chexpert, \"/embeddings/chexpert.pt\")\n",
    "emb_mimic = extract_embeddings(model, train_loader_mimic, device=\"cuda\")\n",
    "torch.save(emb_mimic, \"./embeddings/mimic.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes_alignment(X, Y):\n",
    "    U, _, Vt = torch.linalg.svd(Y.T @ X)\n",
    "    R = U @ Vt\n",
    "    X_aligned = X @ R.T\n",
    "    return X_aligned\n",
    "\n",
    "aligned_chexpert = procrustes_alignment(emb_chexpert, emb_mimic)\n",
    "torch.save(aligned_chexpert, \"/embeddings/chexpert_aligned.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_centroid_distance_pl(embeddings, demographics):\n",
    "    # Convert to a list of unique groups\n",
    "    groups = demographics.unique().to_list()  # Polars syntax\n",
    "    centroids = {}\n",
    "\n",
    "    for g in groups:\n",
    "        # Filter embeddings by group\n",
    "        idxs = [i for i, val in enumerate(demographics) if val == g]\n",
    "        group_emb = embeddings[idxs]\n",
    "        centroids[g] = group_emb.mean(dim=0)\n",
    "\n",
    "    dist = {}\n",
    "    for g1 in groups:\n",
    "        for g2 in groups:\n",
    "            dist[(g1, g2)] = torch.norm(centroids[g1] - centroids[g2]).item()\n",
    "    return dist\n",
    "\n",
    "df_demo = pl.read_csv(os.path.join(dir_chexpert, \"demographics.csv\"))\n",
    "# Assume 'Sex' column exists\n",
    "demographics = df_demo[\"Sex\"].to_list()  # Polars column → Python list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_centroid_distance(embeddings, demographics):\n",
    "    groups = demographics.unique()\n",
    "    centroids = {g: embeddings[demographics==g].mean(dim=0) for g in groups}\n",
    "    dist = {}\n",
    "    for g1 in groups:\n",
    "        for g2 in groups:\n",
    "            dist[(g1,g2)] = torch.norm(centroids[g1] - centroids[g2]).item()\n",
    "    return dist\n",
    "\n",
    "import pandas as pd\n",
    "df_demo = pd.read_csv(os.path.join(dir_chexpert, \"demographics.csv\"))  # must contain 'Sex' column\n",
    "distances = subgroup_centroid_distance(aligned_chexpert, df_demo[\"Sex\"])\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPk3VYQAvkG8XZbveKPAqcC",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
